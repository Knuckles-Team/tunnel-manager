---
services:
  tunnel-manager-mcp:
    image: docker.io/knucklessg1/tunnel-manager:latest
    # build: . # Debug
    container_name: tunnel-manager-mcp
    hostname: tunnel-manager-mcp
    command: ["tunnel-manager-mcp"]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    environment:
      - "HOST=0.0.0.0"
      - "PORT=8002"
      - "TRANSPORT=streamable-http"
      - "TUNNEL_REMOTE_HOST=${TUNNEL_REMOTE_HOST}"
    ports:
      - "8002:8002"
    volumes:
      - ~/.ssh:/root/.ssh:ro

  tunnel-manager-agent:
    image: docker.io/knucklessg1/tunnel-manager:latest
    # build: . # Debug
    container_name: tunnel-manager-agent
    hostname: tunnel-manager-agent
    command: ["tunnel-manager-agent"]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - tunnel-manager-mcp
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    environment:
      - "HOST=0.0.0.0"
      - "PORT=9002"
      - "MCP_URL=http://tunnel-manager-mcp:8002/mcp"
      - "PROVIDER=openai"
      - "OPENAI_BASE_URL=http://localhost:1234/v1"
      - "OPENAI_API_KEY=llama"
      - "MODEL_ID=qwen/qwen3-8b"
      - "DEBUG=False"
      - "ENABLE_WEB_UI=True"
    ports:
      - "9002:9002"
